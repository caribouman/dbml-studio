# Int√©gration Azure Databricks - Guide d'utilisation

Ce guide explique comment utiliser l'int√©gration Azure Databricks dans DBML Studio pour d√©ployer vos sch√©mas de base de donn√©es directement vers Databricks.

## Table des mati√®res

- [Aper√ßu](#aper√ßu)
- [Configuration](#configuration)
- [D√©ploiement de tables](#d√©ploiement-de-tables)
- [Types de donn√©es support√©s](#types-de-donn√©es-support√©s)
- [Exemples](#exemples)
- [D√©pannage](#d√©pannage)

## Aper√ßu

L'int√©gration Databricks vous permet de :

‚úÖ Convertir automatiquement vos diagrammes DBML en SQL DDL Databricks
‚úÖ D√©ployer des tables vers Azure Databricks SQL Warehouse
‚úÖ G√©rer plusieurs catalogues et sch√©mas Unity Catalog
‚úÖ V√©rifier l'existence des tables avant cr√©ation
‚úÖ Voir les r√©sultats d√©taill√©s du d√©ploiement

## Configuration

### 1. Obtenir les credentials Databricks

Vous aurez besoin de :

#### a) Workspace URL
- Format : `https://xxx.cloud.databricks.com`
- Trouvez-le dans l'URL de votre workspace Databricks

#### b) Personal Access Token
1. Dans Databricks, cliquez sur votre profil (en haut √† droite)
2. **User Settings** ‚Üí **Developer** ‚Üí **Access tokens**
3. Cliquez sur **Generate new token**
4. Donnez un nom (ex: "DBML Studio")
5. D√©finissez une dur√©e de vie (ou laissez vide pour illimit√©)
6. Cliquez sur **Generate**
7. **COPIEZ** le token imm√©diatement (il ne sera plus affich√©)

#### c) HTTP Path du SQL Warehouse
1. Dans Databricks, allez dans **SQL Warehouses**
2. S√©lectionnez votre warehouse (ou cr√©ez-en un)
3. Cliquez sur **Connection details**
4. Copiez le **HTTP path**
   - Format : `/sql/1.0/warehouses/xxxxxxxxxxxxx`

### 2. Configurer la connexion dans DBML Studio

#### Application Web
1. Connectez-vous √† DBML Studio
2. Cliquez sur **"Databricks Settings"** dans le header
3. Remplissez le formulaire :
   - **Connection Name** : Nom descriptif (ex: "Prod Workspace")
   - **Workspace URL** : Votre URL Databricks
   - **Access Token** : Le token g√©n√©r√©
   - **HTTP Path** : Le path du SQL Warehouse
   - **Default Catalog** (optionnel) : Catalogue par d√©faut
   - **Default Schema** (optionnel) : Sch√©ma par d√©faut
4. Cliquez sur **"Test Connection"** pour v√©rifier
5. Cliquez sur **"Save Connection"**

#### Application Windows (Electron)
M√™me proc√©dure que ci-dessus.

### 3. Tester la connexion

Si le test r√©ussit, vous verrez :
```
‚úì Connection successful!
```

Si le test √©choue, v√©rifiez :
- L'URL du workspace est correcte (avec https://)
- Le token est valide et n'a pas expir√©
- Le HTTP path est correct
- Le SQL Warehouse est d√©marr√©
- Vous avez les permissions n√©cessaires

## D√©ploiement de tables

### √âtape 1 : Pr√©parer votre DBML

Cr√©ez ou chargez votre sch√©ma DBML. Exemple :

```dbml
Table users {
  id integer [pk, increment]
  username varchar(50) [not null, unique]
  email varchar(100) [not null, unique]
  created_at timestamp [default: `now()`]

  Note: 'Table des utilisateurs'
}

Table posts {
  id integer [pk, increment]
  user_id integer [not null, ref: > users.id]
  title varchar(200) [not null]
  content text
  published boolean [default: false]
  created_at timestamp [default: `now()`]

  Note: 'Articles de blog'
}
```

### √âtape 2 : Ouvrir le dialog de d√©ploiement

1. Assurez-vous d'avoir du code DBML dans l'√©diteur
2. Cliquez sur **"Deploy to Databricks"** (bouton rouge)

### √âtape 3 : S√©lectionner la cible

1. **Catalog** : S√©lectionnez le catalogue cible
   - Ex: `main`, `dev`, `prod`
2. **Schema** : S√©lectionnez le sch√©ma cible
   - Ex: `default`, `bronze`, `silver`, `gold`

### √âtape 4 : S√©lectionner les tables

1. Cochez les tables que vous voulez d√©ployer
2. Utilisez **"Select All"** pour tout s√©lectionner
3. D√©cochez les tables que vous ne voulez pas cr√©er

### √âtape 5 : D√©ployer

1. Cliquez sur **"Deploy X Tables"**
2. Attendez la fin du d√©ploiement
3. Consultez les r√©sultats :
   - **Created** : Tables cr√©√©es avec succ√®s ‚úÖ
   - **Skipped** : Tables d√©j√† existantes ‚ö†Ô∏è
   - **Failed** : Erreurs lors de la cr√©ation ‚ùå

### R√©sultat du d√©ploiement

Exemple de r√©sultat :

```
Deployment Results

Total: 2
Created: 2
Skipped: 0
Failed: 0

‚úì users: Table created successfully
‚úì posts: Table created successfully
```

## Types de donn√©es support√©s

Le convertisseur DBML ‚Üí Databricks mappe automatiquement les types :

| DBML Type | Databricks Type |
|-----------|----------------|
| `int`, `integer` | `INT` |
| `smallint` | `SMALLINT` |
| `bigint` | `BIGINT` |
| `tinyint` | `TINYINT` |
| `decimal`, `numeric` | `DECIMAL` |
| `float`, `real` | `FLOAT` |
| `double` | `DOUBLE` |
| `varchar`, `char`, `text`, `string` | `STRING` |
| `date` | `DATE` |
| `datetime`, `timestamp` | `TIMESTAMP` |
| `boolean`, `bool` | `BOOLEAN` |
| `binary`, `blob` | `BINARY` |
| `json`, `jsonb` | `STRING` |
| `uuid` | `STRING` |

**Note** : Databricks ne supporte pas nativement le type `TIME`, il est converti en `STRING`.

## Exemples

### Exemple 1 : Table simple

**DBML :**
```dbml
Table products {
  id int [pk]
  name varchar(100) [not null]
  price decimal(10,2)

  Note: 'Product catalog'
}
```

**SQL g√©n√©r√© :**
```sql
CREATE TABLE IF NOT EXISTS main.default.products (
  id INT NOT NULL,
  name STRING NOT NULL,
  price DECIMAL,
  PRIMARY KEY (id)
)
COMMENT 'Product catalog';
```

### Exemple 2 : Table avec commentaires sur colonnes

**DBML :**
```dbml
Table employees {
  employee_id bigint [pk, note: 'Unique employee identifier']
  first_name varchar(50) [not null, note: 'Employee first name']
  last_name varchar(50) [not null, note: 'Employee last name']
  hire_date date [note: 'Date of hire']
}
```

**SQL g√©n√©r√© :**
```sql
CREATE TABLE IF NOT EXISTS main.default.employees (
  employee_id BIGINT NOT NULL COMMENT 'Unique employee identifier',
  first_name STRING NOT NULL COMMENT 'Employee first name',
  last_name STRING NOT NULL COMMENT 'Employee last name',
  hire_date DATE COMMENT 'Date of hire',
  PRIMARY KEY (employee_id)
);
```

### Exemple 3 : D√©ploiement vers diff√©rents environnements

**D√©veloppement :**
- Catalog : `dev`
- Schema : `bronze`
- Tables : Toutes

**Production :**
- Catalog : `prod`
- Schema : `gold`
- Tables : S√©lection manuelle

## Fonctionnalit√©s avanc√©es

### V√©rification d'existence

Le syst√®me v√©rifie automatiquement si une table existe avant de la cr√©er :

- ‚úÖ **Table n'existe pas** ‚Üí Cr√©ation
- ‚ö†Ô∏è **Table existe d√©j√†** ‚Üí Ignor√©e (pas de modification)

### Pr√©visualisation SQL

Pour voir le SQL g√©n√©r√© sans d√©ployer, utilisez l'API :

```javascript
POST /api/databricks/convert
{
  "dbml_code": "Table users { ... }"
}
```

R√©ponse :
```json
{
  "success": true,
  "tables": [
    {
      "tableName": "users",
      "ddl": "CREATE TABLE IF NOT EXISTS users (...)"
    }
  ]
}
```

## D√©pannage

### Erreur : "No Databricks connection configured"

**Cause** : Aucune connexion Databricks n'est configur√©e.
**Solution** : Allez dans "Databricks Settings" et configurez votre connexion.

### Erreur : "Connection test failed"

**Causes possibles** :
1. Token invalide ou expir√©
2. HTTP path incorrect
3. SQL Warehouse arr√™t√©
4. Permissions insuffisantes

**Solution** :
1. V√©rifiez que le token est valide
2. Red√©marrez le SQL Warehouse dans Databricks
3. V√©rifiez les permissions sur le workspace

### Erreur : "Failed to list catalogs"

**Cause** : Permissions insuffisantes sur Unity Catalog.
**Solution** : Assurez-vous d'avoir les permissions `USE CATALOG` sur les catalogues.

### Table marqu√©e comme "Failed"

**Causes possibles** :
1. Permissions insuffisantes sur le sch√©ma
2. Type de donn√©es non support√©
3. Nom de table r√©serv√©

**Solution** :
1. V√©rifiez les permissions `CREATE TABLE` sur le sch√©ma
2. Consultez les logs d'erreur d√©taill√©s
3. Renommez la table si n√©cessaire

### Les relations (foreign keys) ne sont pas cr√©√©es

**Note** : Actuellement, seules les PRIMARY KEY sont cr√©√©es.
Les FOREIGN KEY Databricks n√©cessitent des contraintes suppl√©mentaires.
**Solution future** : Une prochaine version ajoutera le support des FK.

## S√©curit√©

### Stockage des credentials

Les credentials Databricks sont stock√©s dans la base de donn√©es SQLite locale :

- **Application Web** : Dans `app/data/dbml-studio.db`
- **Application Windows** : Dans `%APPDATA%\DBML Studio\data\`

**‚ö†Ô∏è Important** :
- Les tokens sont stock√©s en clair pour le moment
- Ne partagez pas votre base de donn√©es
- Utilisez des tokens avec dur√©e de vie limit√©e
- R√©voquezles tokens inutilis√©s

### Recommandations

1. **Utilisez des tokens d√©di√©s** :
   - Cr√©ez un token sp√©cifique pour DBML Studio
   - Donnez-lui un nom identifiable
   - D√©finissez une dur√©e de vie (ex: 90 jours)

2. **Limitez les permissions** :
   - Utilisez un service principal si possible
   - Donnez uniquement les permissions n√©cessaires
   - `USE CATALOG`, `USE SCHEMA`, `CREATE TABLE`

3. **Rotation des tokens** :
   - Renouvelez les tokens r√©guli√®rement
   - Supprimez les anciens tokens de Databricks

## API Reference

Pour les d√©veloppeurs qui veulent int√©grer :

### Endpoints disponibles

```
POST   /api/databricks/connection       # Sauvegarder connexion
GET    /api/databricks/connection       # R√©cup√©rer connexion
DELETE /api/databricks/connection       # Supprimer connexion
POST   /api/databricks/test            # Tester connexion
GET    /api/databricks/catalogs        # Lister catalogues
GET    /api/databricks/schemas/:catalog # Lister sch√©mas
POST   /api/databricks/deploy          # D√©ployer tables
POST   /api/databricks/convert         # Convertir DBML en SQL
```

Tous les endpoints n√©cessitent une authentification JWT.

## Am√©liorations futures

Fonctionnalit√©s pr√©vues :

- [ ] Chiffrement des tokens d'acc√®s
- [ ] Support des contraintes FOREIGN KEY
- [ ] Mode "update" pour modifier les tables existantes
- [ ] Pr√©visualisation SQL dans l'UI
- [ ] Historique des d√©ploiements
- [ ] Support des vues Databricks
- [ ] Support des table properties (Delta, partitioning)
- [ ] Export des logs de d√©ploiement

## Support

Pour toute question ou bug :

1. Consultez la documentation Databricks : [docs.databricks.com](https://docs.databricks.com/)
2. V√©rifiez les logs : Menu **File** ‚Üí **View Logs** (Electron)
3. Ouvrez un ticket GitHub avec :
   - Description du probl√®me
   - DBML utilis√© (sans donn√©es sensibles)
   - Message d'erreur complet
   - Version de DBML Studio

---

**Bon d√©ploiement ! üöÄ**
